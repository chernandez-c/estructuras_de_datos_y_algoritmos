---
title: "M√≥dulo 7 ‚Äì Algoritmos de ordenaci√≥n"
author: "Curso de Introducci√≥n a Estructuras de Datos y Algoritmos"
date: "21 de agosto de 2025"
toc: true
number-sections: true
---

# M√≥dulo 7 ‚Äì Algoritmos de Ordenaci√≥n: Imponiendo el Orden en el Caos

## 0. Motivaci√≥n: El Orden como Prerrequisito de la Eficiencia üèõÔ∏è

En un mundo saturado de datos, la informaci√≥n en su estado crudo es a menudo ca√≥tica e inmanejable. La **ordenaci√≥n** es el proceso fundamental mediante el cual transformamos este caos en una estructura inteligible. Es, quiz√°s, la tarea m√°s realizada en computaci√≥n, no como un fin en s√≠ misma, sino como un paso crucial que habilita operaciones m√°s complejas y eficientes.

La filosof√≠a detr√°s de la ordenaci√≥n es simple: **invertir trabajo ahora para ahorrar mucho m√°s trabajo despu√©s**.

  * **B√∫squeda eficiente**: Como ya vimos, sin orden, encontrar un elemento requiere una b√∫squeda lineal ($O(n)$). Con orden, la b√∫squeda binaria lo encuentra en tiempo logar√≠tmico ($O(\\log n)$). Esta es la diferencia entre encontrar un libro en una biblioteca desorganizada frente a una catalogada por el sistema decimal Dewey.
  * **An√°lisis de datos**: ¬øCu√°l es el valor mediano de un conjunto? ¬øCu√°les son los elementos duplicados? ¬øQu√© valores est√°n en el percentil 99? Estas preguntas son triviales de responder sobre datos ordenados, pero computacionalmente costosas sobre datos desordenados.
  * **Fundamento algor√≠tmico**: Muchos algoritmos avanzados presuponen que los datos de entrada est√°n ordenados. Desde encontrar los dos puntos m√°s cercanos en un plano hasta la compresi√≥n de datos, la ordenaci√≥n es el primer paso indispensable.

El estudio de los algoritmos de ordenaci√≥n es un viaje por la historia de la algoritmia. Nos ense√±a sobre diferentes enfoques para resolver un mismo problema (fuerza bruta, divide y vencer√°s) y nos obliga a pensar en los *trade-offs* fundamentales: tiempo vs. memoria, simplicidad vs. eficiencia, y el comportamiento en el mejor, peor y caso promedio.

-----

-----

## 1. Algoritmos Simples (Complejidad Cuadr√°tica)

Estos algoritmos son conceptualmente sencillos y f√°ciles de implementar, pero su rendimiento de $O(n^2)$ los hace inviables para conjuntos de datos que no sean peque√±os. Son, sin embargo, excelentes herramientas pedag√≥gicas para entender los fundamentos de la ordenaci√≥n.

### 1.1 Bubble Sort (Ordenaci√≥n por Burbuja)

  * **Filosof√≠a**: La "fuerza bruta" paciente. Compara repetidamente pares de elementos adyacentes y los intercambia si est√°n en el orden incorrecto. En cada pasada completa, el siguiente elemento m√°s grande "burbujea" hasta su posici√≥n final.
  * **Analog√≠a**: Imagina una fila de personas de diferentes alturas. En cada paso, miras a dos personas contiguas y, si la de la izquierda es m√°s alta que la de la derecha, las intercambias. Si repites este proceso a lo largo de toda la fila suficientes veces, la gente terminar√° ordenada por altura.

#### Pseudoc√≥digo

```text
procedimiento bubbleSort(lista):
    n ‚Üê longitud(lista)
    hacer
        intercambiado ‚Üê falso
        para i desde 0 hasta n-2:
            si lista[i] > lista[i+1]:
                intercambiar(lista[i], lista[i+1])
                intercambiado ‚Üê verdadero
        n ‚Üê n - 1 // Optimizaci√≥n: el √∫ltimo elemento ya est√° en su sitio
    mientras intercambiado
```

  * **An√°lisis**: Su rendimiento es pobre ($O(n^2)$) porque solo mueve los elementos de uno en uno. Su √∫nica ventaja real es su capacidad de detectar si la lista ya est√° ordenada (terminando en una sola pasada, $O(n)$).

### 1.2 Insertion Sort (Ordenaci√≥n por Inserci√≥n)

  * **Filosof√≠a**: Construir el orden de forma incremental. Recorre la lista, tomando cada elemento y "desliz√°ndolo" hacia la izquierda en la parte ya ordenada de la lista hasta encontrar su lugar correcto.
  * **Analog√≠a**: Es exactamente como la mayor√≠a de la gente ordena una mano de cartas. Tomas una carta a la vez y la insertas en la posici√≥n correcta entre las cartas que ya tienes ordenadas en la otra mano.

#### Pseudoc√≥digo

```text
procedimiento insertionSort(lista):
    para i desde 1 hasta longitud(lista)-1:
        clave ‚Üê lista[i]
        j ‚Üê i - 1
        // Desplazar elementos mayores que la clave hacia la derecha
        mientras j ‚â• 0 y lista[j] > clave:
            lista[j+1] ‚Üê lista[j]
            j ‚Üê j - 1
        lista[j+1] ‚Üê clave
```

  * **An√°lisis**: Aunque su peor caso sigue siendo $O(n^2)$, es significativamente m√°s eficiente en la pr√°ctica que Bubble Sort. Su gran ventaja es su rendimiento **adaptativo**: para listas que est√°n **casi ordenadas**, su complejidad se acerca a $O(n)$, lo que lo hace muy √∫til en ciertos escenarios.

### 1.3 Selection Sort (Ordenaci√≥n por Selecci√≥n)

  * **Filosof√≠a**: El m√©todo met√≥dico. Divide la lista en dos partes: una ordenada (al principio) y una desordenada (el resto). En cada paso, encuentra el elemento m√°s peque√±o de la parte desordenada y lo intercambia con el primer elemento de esa parte, expandiendo as√≠ la secci√≥n ordenada.
  * **Analog√≠a**: Es como un director de casting que tiene que poner en fila a un grupo de actores por altura. Primero, busca al actor m√°s bajo de todo el grupo y lo pone al principio. Luego, ignora a esa persona y busca al m√°s bajo del resto, coloc√°ndolo en la segunda posici√≥n. Repite hasta que todos est√°n en fila.

#### Pseudoc√≥digo

```text
procedimiento selectionSort(lista):
    n ‚Üê longitud(lista)
    para i desde 0 hasta n-2:
        √≠ndice_m√≠nimo ‚Üê i
        para j desde i+1 hasta n-1:
            si lista[j] < lista[√≠ndice_m√≠nimo]:
                √≠ndice_m√≠nimo ‚Üê j
        intercambiar(lista[i], lista[√≠ndice_m√≠nimo])
```

  * **An√°lisis**: Su complejidad es **siempre** $O(n^2)$, sin importar el estado inicial de la lista. Su principal caracter√≠stica es que minimiza el n√∫mero de intercambios, lo que podr√≠a ser √∫til si la operaci√≥n de intercambio es muy costosa.

-----

## 2. Algoritmos Eficientes 

**Complejidad $O(n \log n)$**

Estos algoritmos utilizan estrategias m√°s sofisticadas, t√≠picamente basadas en el paradigma **"Divide y Vencer√°s"**, para lograr una eficiencia muy superior. Son el est√°ndar de oro para la ordenaci√≥n de prop√≥sito general.

### **2.1 Merge Sort (Ordenaci√≥n por Mezcla)**

  * **Filosof√≠a**: La organizaci√≥n recursiva. La idea es que es trivial ordenar una lista de un solo elemento. Merge Sort divide recursivamente la lista a la mitad hasta que solo quedan sublistas de un elemento. Luego, combina (fusiona o "merge") esas sublistas de manera ordenada hasta reconstruir la lista completa.
  * **El paso clave**: La funci√≥n `fusionar(izquierda, derecha)` es el coraz√≥n del algoritmo. Toma dos sublistas ya ordenadas y las combina en una nueva lista ordenada en tiempo lineal $O(n)$.

#### Pseudoc√≥digo

```text
funci√≥n mergeSort(lista):
    si longitud(lista) ‚â§ 1:
        devolver lista
    
    medio ‚Üê longitud(lista) / 2
    izquierda ‚Üê sublista(lista, 0, medio-1)
    derecha ‚Üê sublista(lista, medio, fin)
    
    izquierda_ordenada ‚Üê mergeSort(izquierda)
    derecha_ordenada ‚Üê mergeSort(derecha)
    
    devolver fusionar(izquierda_ordenada, derecha_ordenada)

procedimiento fusionar(izquierda, derecha):
    // C√≥digo para combinar dos listas ordenadas en una nueva
    ...
```

  * **An√°lisis**: Su complejidad es **siempre** $O(n \\log n)$, lo que lo hace muy predecible y fiable. Su principal desventaja es que requiere espacio adicional ($O(n)$) para almacenar las sublistas, lo que puede ser un problema con memoria limitada. Es un algoritmo **estable**, lo que significa que mantiene el orden relativo de los elementos con claves iguales.

### 2.2 Quicksort (Ordenaci√≥n R√°pida)

  * **Filosof√≠a**: La partici√≥n inteligente. Es otro algoritmo de "Divide y Vencer√°s", pero funciona de manera diferente.
    1.  **Elegir un pivote**: Se selecciona un elemento de la lista (el pivote).
    2.  **Particionar**: Se reorganiza la lista de modo que todos los elementos menores que el pivote queden a su izquierda, y todos los mayores queden a su derecha.
    3.  **Recursi√≥n**: Se aplica Quicksort recursivamente a las dos sublistas (la de los menores y la de los mayores).
  * **El paso clave**: La eficiencia de Quicksort depende cr√≠ticamente de la elecci√≥n del pivote. Un buen pivote divide la lista en dos mitades de tama√±o similar. Un mal pivote (el menor o mayor elemento) puede degradar el rendimiento a $O(n^2)$.

#### Pseudoc√≥digo (Conceptual)**

```text
funci√≥n quickSort(lista):
    si longitud(lista) ‚â§ 1:
        devolver lista
    
    pivote ‚Üê elegir_pivote(lista)
    menores, iguales, mayores ‚Üê particionar(lista, pivote)
    
    resultado ‚Üê concatenar(quickSort(menores), iguales, quickSort(mayores))
    devolver resultado
```

  * **An√°lisis**: A pesar de su peor caso de $O(n^2)$, su rendimiento **promedio** es $O(n \\log n)$ con constantes muy bajas, lo que lo hace extremadamente r√°pido en la pr√°ctica. Funciona *in-place*, requiriendo solo $O(\\log n)$ de espacio en la pila de recursi√≥n. Es el algoritmo de ordenaci√≥n de prop√≥sito general m√°s utilizado en las bibliotecas est√°ndar de muchos lenguajes.

-----

## 3. Comparaci√≥n y Criterios de Elecci√≥n

| Algoritmo | Complejidad Promedio | Peor Caso | Espacio Adicional | Estable | Comentarios |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Bubble Sort** | $O(n^2)$ | $O(n^2)$ | $O(1)$ | ‚úÖ | Solo para fines educativos. |
| **Insertion Sort**| $O(n^2)$ | $O(n^2)$ | $O(1)$ | ‚úÖ | Eficiente en listas peque√±as o casi ordenadas. |
| **Selection Sort**| $O(n^2)$ | $O(n^2)$ | $O(1)$ | ‚ùå | Predecible pero lento. Minimiza intercambios. |
| **Merge Sort** | $O(n \\log n)$| $O(n \\log n)$| $O(n)$ | ‚úÖ | Muy fiable. Ideal para ordenaci√≥n externa. |
| **Quicksort** | $O(n \\log n)$| $O(n^2)$ | $O(\\log n)$ | ‚ùå | Generalmente el m√°s r√°pido en la pr√°ctica. |

**¬øQu√© algoritmo elegir?** ü§î

  * Para **listas peque√±as** (ej. \< 20 elementos), **Insertion Sort** suele ser el m√°s r√°pido.
  * Para una **garant√≠a de rendimiento** y si la **estabilidad** es importante, **Merge Sort** es la elecci√≥n segura.
  * Para el **m√°ximo rendimiento promedio** en memoria, **Quicksort** es el rey.
  * Para **datos masivos** que no caben en memoria, una variante de **Merge Sort** (ordenaci√≥n externa) es la √∫nica opci√≥n.



**¬øPara qu√© se usan en computaci√≥n y bioinform√°tica?**

* **Insertion sort**: ordenar peque√±as listas (ej. registros temporales).
* **Merge sort**: ordenaci√≥n externa, como ordenar archivos gen√≥micos de varios gigabytes en disco.
* **Quicksort**: ordenaci√≥n interna en memoria, ampliamente usado en librer√≠as est√°ndar, siendo el algoritmo por defecto en muchas librer√≠as de C, Java o Python.
* **Ordenaci√≥n en bioinform√°tica**: 
  - Clasificaci√≥n de secuencias de ADN/prote√≠nas antes de alineamientos masivos.
  - Preparaci√≥n de grandes matrices de expresi√≥n g√©nica para an√°lisis estad√≠sticos.
  - Preprocesamiento de datos de lecturas en secuenciaci√≥n masiva.

---

## 5. Conclusiones

* Los algoritmos **cuadr√°ticos** son simples, √∫tiles solo para listas peque√±as o fines pedag√≥gicos.
* **Merge sort** y **quicksort** ofrecen rendimiento $O(n \log n)$ y son los m√°s usados en la pr√°ctica.
* La **estabilidad** y el **uso de memoria** son criterios importantes en la elecci√≥n.
* La ordenaci√≥n es clave para optimizar procesos posteriores como b√∫squedas y an√°lisis de grandes vol√∫menes de datos.

---

## 6. Ejercicios de autoevaluaci√≥n

1. Ordena manualmente la lista `[5,2,9,1,5,6]` con bubble sort, mostrando cada pasada.
2. ¬øPor qu√© insertion sort es m√°s eficiente que bubble sort en la pr√°ctica?
3. Explica por qu√© merge sort es estable y selection sort no lo es.
4. Analiza el peor caso de quicksort. ¬øC√≥mo puede mitigarse?
5. Dise√±a un algoritmo que combine **insertion sort** y **quicksort** para aprovechar lo mejor de ambos.
6. ¬øQu√© algoritmo usar√≠as para ordenar un archivo de 50 GB almacenado en disco? Justifica tu respuesta.

---

## Referencias

* Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. *Introduction to Algorithms*. MIT Press.
* Weiss, M. A. *Data Structures and Algorithm Analysis*. Pearson.
* Sedgewick, R., & Wayne, K. *Algorithms*. Addison-Wesley.
* Goodrich, M. T., Tamassia, R., & Goldwasser, M. H. *Data Structures and Algorithms in Java*. Wiley.
